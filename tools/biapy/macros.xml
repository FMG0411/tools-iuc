<macros>
    <token name="@TOOL_VERSION@">3.6.4</token>
    <token name="@PYTHON_VERSION@">3.10</token>
    <token name="@VERSION_SUFFIX@">0</token>
    <token name="@PROFILE@">25.0</token>

    <xml name="requirements">
        <requirements>
            <requirement type="package" version="@PYTHON_VERSION@">python</requirement>
            <requirement type="package" version="@TOOL_VERSION@">biapy</requirement>
        </requirements>
    </xml>
    <xml name="creators">
        <creator>
            <person givenName="Daniel" familyName="Franco" url="https://danifranco.github.io/" identifier="https://orcid.org/0000-0002-1109-110X" />
        </creator>
    </xml>
    <xml name="citations">
        <citations>
            <citation type="doi">10.1038/s41592-025-02699-y</citation>
            <yield/>
        </citations>
    </xml>

    <!-- Q9 -->
    <macro name="train_raw_param">
        <param name="raw_train" type="data" format="tiff,png,jpg,h5" multiple="true" label="Specify the training raw images" help="In this step, you need to select the images to train the network. All these images must have the same number of channels. It's also important that each channel contains the same type of information to avoid confusing the model. A more detailed description can be found in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/how_it_works.html)"/>
    </macro>

    <macro name="train_raw_param_opt">
        <param name="raw_train" type="data" optional="true" format="tiff,png,jpg,h5" multiple="true" label="Specify the training raw images" help="In this step, you need to select the images to train the network. All these images must have the same number of channels. It's also important that each channel contains the same type of information to avoid confusing the model. A more detailed description can be found in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/how_it_works.html)"/>
    </macro>

    <!-- Q10 -->
    <macro name="train_gt_param">
        <param name="gt_train" type="data" format="tiff,png,jpg,h5" multiple="true" label="Specify the training ground truth (target) images" help="In this step, you need to select the ground truth (target) images to train the model. The target vary depending on the workflow: For Semantic segmentation, single-channel images are expected, specifically semantic masks. In these masks, each pixel will have a specific integer value corresponding to the class it belongs to. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. Additionally, the number of classes to predict will be automatically extracted based on the different classes found in the images. For Instance segmentation, one or two-channel images are expected. The first channel must always contain the instance masks, where each pixel has an integer value representing the object it belongs to. If two channels are provided, the second channel should contain the class of each instance. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. If two channels are present, as in semantic segmentation, the number of classes to predict will be automatically extracted from the different classes found. For Detection, files with the coordinates of object centers (centroids) are expected. The checks include: 1) ensuring the files can be read correctly; 2) verifying that the required columns for creating the coordinates are present in each file. Additionally, if the files contain a 'class' column, the number of classes will automatically be set to the highest value found in that column across all files. For Super-resolution, high-resolution images are expected, meaning these images will be 2x or 4x larger than the versions in the 'Train data (raw)' folder from the previous step. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For example, if the images are uint8, their values should be between 0 and 255 across all images. For Image-to-Image, images are expected. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For instance, if the images are uint8, the values should range between 0 and 255 across all images. You can find more information about each workflow and examples of dataset in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/select_workflow.html)"/>
    </macro>
    <macro name="train_gt_param_opt">
        <param name="gt_train" type="data"  optional="true" format="tiff,png,jpg,h5" multiple="true" label="Specify the training ground truth (target) images" help="In this step, you need to select the ground truth (target) images to train the model. The target vary depending on the workflow: For Semantic segmentation, single-channel images are expected, specifically semantic masks. In these masks, each pixel will have a specific integer value corresponding to the class it belongs to. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. Additionally, the number of classes to predict will be automatically extracted based on the different classes found in the images. For Instance segmentation, one or two-channel images are expected. The first channel must always contain the instance masks, where each pixel has an integer value representing the object it belongs to. If two channels are provided, the second channel should contain the class of each instance. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. If two channels are present, as in semantic segmentation, the number of classes to predict will be automatically extracted from the different classes found. For Detection, files with the coordinates of object centers (centroids) are expected. The checks include: 1) ensuring the files can be read correctly; 2) verifying that the required columns for creating the coordinates are present in each file. Additionally, if the files contain a 'class' column, the number of classes will automatically be set to the highest value found in that column across all files. For Super-resolution, high-resolution images are expected, meaning these images will be 2x or 4x larger than the versions in the 'Train data (raw)' folder from the previous step. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For example, if the images are uint8, their values should be between 0 and 255 across all images. For Image-to-Image, images are expected. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For instance, if the images are uint8, the values should range between 0 and 255 across all images. You can find more information about each workflow and examples of dataset in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/select_workflow.html)"/>
    </macro>

    <!-- Q11 -->
    <macro name="test_raw_param">
        <param name="raw_test" type="data" format="tiff,png,jpg,h5" multiple="true" label="Specify the test raw images" help="In this step, you need to select the images for testing the network. All these images must have the same number of channels. It's also important that each channel contains the same type of information to avoid confusing the model"/>
    </macro>
    <macro name="test_raw_param_opt">
        <param name="raw_test" type="data" format="tiff,png,jpg,h5" optional="true" multiple="true" label="Specify the test raw images" help="In this step, you need to select the images for testing the network. All these images must have the same number of channels. It's also important that each channel contains the same type of information to avoid confusing the model"/>
    </macro>

    <!-- Q13 -->
    <macro name="test_gt_param">
        <param name="gt_test" type="data" format="tiff,png,jpg,h5" multiple="true" label="Specify the test ground truth (target) images" help="In this step, you need to select the ground truth (target) images to test the model. The target vary depending on the workflow: For Semantic segmentation, single-channel images are expected, specifically semantic masks. In these masks, each pixel will have a specific integer value corresponding to the class it belongs to. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. Additionally, the number of classes to predict will be automatically extracted based on the different classes found in the images. For Instance segmentation, one or two-channel images are expected. The first channel must always contain the instance masks, where each pixel has an integer value representing the object it belongs to. If two channels are provided, the second channel should contain the class of each instance. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. If two channels are present, as in semantic segmentation, the number of classes to predict will be automatically extracted from the different classes found. For Detection, files with the coordinates of object centers (centroids) are expected. The checks include: 1) ensuring the files can be read correctly; 2) verifying that the required columns for creating the coordinates are present in each file. Additionally, if the files contain a 'class' column, the number of classes will automatically be set to the highest value found in that column across all files. For Super-resolution, high-resolution images are expected, meaning these images will be 2x or 4x larger than the versions in the 'Train data (raw)' folder from the previous step. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For example, if the images are uint8, their values should be between 0 and 255 across all images. For Image-to-Image, images are expected. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For instance, if the images are uint8, the values should range between 0 and 255 across all images. You can find more information about each workflow and examples of dataset in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/select_workflow.html)"/>
    </macro>
    <macro name="test_gt_param_opt">
        <param name="gt_test" type="data" format="tiff,png,jpg,h5" optional="true" multiple="true" label="Specify the test ground truth (target) images" help="In this step, you need to select the ground truth (target) images to test the model. The target vary depending on the workflow: For Semantic segmentation, single-channel images are expected, specifically semantic masks. In these masks, each pixel will have a specific integer value corresponding to the class it belongs to. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. Additionally, the number of classes to predict will be automatically extracted based on the different classes found in the images. For Instance segmentation, one or two-channel images are expected. The first channel must always contain the instance masks, where each pixel has an integer value representing the object it belongs to. If two channels are provided, the second channel should contain the class of each instance. The checks performed include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels. If two channels are present, as in semantic segmentation, the number of classes to predict will be automatically extracted from the different classes found. For Detection, files with the coordinates of object centers (centroids) are expected. The checks include: 1) ensuring the files can be read correctly; 2) verifying that the required columns for creating the coordinates are present in each file. Additionally, if the files contain a 'class' column, the number of classes will automatically be set to the highest value found in that column across all files. For Super-resolution, high-resolution images are expected, meaning these images will be 2x or 4x larger than the versions in the 'Train data (raw)' folder from the previous step. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For example, if the images are uint8, their values should be between 0 and 255 across all images. For Image-to-Image, images are expected. The checks include: 1) ensuring all images can be read correctly; 2) verifying that all images have the same number of input channels; 3) checking that all images are within the same value range. For instance, if the images are uint8, the values should range between 0 and 255 across all images. You can find more information about each workflow and examples of dataset in [BiaPy documentation](https://biapy.readthedocs.io/en/latest/get_started/select_workflow.html)"/>
    </macro>
</macros>
